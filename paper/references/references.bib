%References
@ARTICLE{AKA91,
  author =          "D.W. Aha and D. Kibler and M.K. Albert",
  title =           "Instance-based Learning Algorithms",
  journal =         "Machine Learning",
  year =            "1991",
  volume =          "6",
  number =          "",
  pages =           "37--66",
} % ------------------------------------------------------------------------
@ARTICLE{BL97,
  author =        "A.L. Blum and P. Langley",
  title =         "Selection of Relevant Features and Examples in Machine Learning",
  journal =       "Artificial Intelligence",
  editor =        "R. Greiner and D. Subramanian",
  year =          "1997",
  volume =        "97",
  number =        "1-2",
  pages =         "245-271",
} % ------------------------------------------------------------------------
@ARTICLE{DL97,
  author =        "M. Dash and H. Liu",
  title =         "Feature Selection for Classification",
  journal =       "Intelligent Data Analisys",
  year =          "1997",
  volume =        "1",
  number =        "3",
  pages =         "131--56",
} % ------------------------------------------------------------------------
@inproceedings{DLM00,
    author = "M. Dash and H. Liu and H. Motoda",
    title = "Consistency Based Feature Selection",
    booktitle = "Pacific-Asia Conf. on Knowledge Discovery and Data Mining",he more uncertain we are
    pages = "98-109",
    year = "2000",
} % ------------------------------------------------------------------------
@TECHREPORT{Doa92,
  author =          "J. Doak",
  title =           "An Evaluation of Feature Selection Methods and their Application to Computer Security",
  year =            "1992",
  institution =     "University of California, Department of Computer Science",
  number =          "CSE-92-18",
  address =         "Davis, CA",
} % ------------------------------------------------------------------------
@ARTICLE{GE03,
  author =          "I. Guyon and A. Elisseeff",
  title =           "An Introduction to Variable and Feature Selection",
  journal =         "Journal of Machine Learning Research",
  year =            "2003",
  volume =          "3",
  number =          "",
  pages =           "1157--1182",
} % ------------------------------------------------------------------------
@PHDTHESIS{Hall99CFSThesis,
  author =      "M.A. Hall",
  title =       "Correlation-based Feature Selection for Machine Learning",
  school =      "University of Waikato, Department of Computer Science",
  year =        "1999",
  address =     "Hamilton, New Zealand",
} % ------------------------------------------------------------------------
@INPROCEEDINGS{KJ95,
  author =        "R. Kohavi and G.H. John",
  title =         "Automatic Parameter Selection by Minimizing Estimated Error",
  booktitle =     "12th Int. Conf. on Machine Learning",
  year =          "1995",
  pages =         "304--312",
  address   =     "San Francisco",
} % ------------------------------------------------------------------------
@ARTICLE{KJ97,
  author =        "R. Kohavi and G.H. John",
  title =         "Wrappers for Feature Subset Selection",
  journal =       "Artificial Intelligence",
  year =          "1997",
  volume =        "1-2",
  pages =         "273-324",
} % ------------------------------------------------------------------------
@INPROCEEDINGS{Lan94,
  author =        "P. Langley",
  title =         "Selection of Relevant Features in Machine Learning",
  booktitle =     "Procs. Of the AAAI Fall Symposium on Relevance",
  year =          "1994",
  pages =         "140-144",
} % ------------------------------------------------------------------------
@INPROCEEDINGS{LY04,
  author =        "L. Yu and H. Liu",
  title =         "Redundancy Based Feature Selection for Microarray Data",
  booktitle =     "10th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining",
  year =          "2004",
  pages =         "",
  addres =        "Seattle, Washington",
} % ------------------------------------------------------------------------
@BOOK{LM98,
  AUTHOR =       {H. Liu and H. Motoda},
  TITLE =        {Feature Selection for Knowlegde Discovery and Data Mining},
  PUBLISHER =    {Kluwer Academic Publishers},
  YEAR =         {1998},
  address =      {London, UK},
}% ------------------------------------------------------------------------
@ARTICLE{LY05,
  author =        "H. Liu and L. Yu",
  title =         "Toward Integrating Feature Selection Algorithms for Classification and Clustering",
  journal =       "IEEE Trans. on Knowledge and Data Eng.",
  year =          "2005",
  volume =        "17",
  number =        "3",
  pages =         "1--12",
} % ------------------------------------------------------------------------
@BOOK{Mit97,
  author =       "T. Mitchell",
  title =        "Machine Learning",
  publisher =    "McGraw Hill",
  year =         "1997",
} % ------------------------------------------------------------------------
@BOOK{Qui93,
  author =        "J. R. Quinlan",
  title =         "C4.5: Programs for Machine Learning",
  publisher =     "Morgan Kaufmann",
  year =          "1993",
  address =       "San Mateo, California",
} % ------------------------------------------------------------------------
@BOOK{WF05,
  author =        "I.H. Witten and E. Frank",
  title =         "Data Mining: Practical machine learning tools and techniques",
  publisher =     "Morgan Kaufmann",
  year =          "2005",
  edition =       "2",
  address =       "San Francisco",
} % ------------------------------------------------------------------------

%@BOOK{witten05,
%  AUTHOR = {Ian H. Witten and Eibe Frank},
%  TITLE = {Data Mining: Practical Machine Learning Tools and Techniques},
%  PUBLISHER = {Morgan Kaufmann},
%  YEAR = 2005,
%  ADDRESS = {San Francisco},
%  EDITION = 2,
%  HTTP = {http://www.cs.waikato.ac.nz/~ml/weka/book.html}
%}
%
%@misc{SM05,
%       author = {J. Sayyad Shirabad and T. J. Menzies},
%       year = {2005},
%       title = {The {PROMISE} Repository of Software Engineering Databases},
%       url = {http://promise.site.uottawa.ca/SERepository},
%       howpublished = {School of Information Technology and Engineering,
%                       University of Ottawa, Canada}
}% ------------------------------------------------------------------------

@Article{mccabe76,
       title   = {A Complexity Measure},
       author  = {T. J. McCabe},
       pages   = {308--320},
       journal = {IEEE Transactions on Software Engineering},
       year    = {1976},
       volume  = {2},
       month   = {December},
       number  = {4}
}% ------------------------------------------------------------------------

@book{fenton97,
    author    = {N. E. Fenton and S. L. Pfleeger},
    title     = {Software Metrics: a Rigorous \& Practical Approach},
    publisher = {International Thompson Press},
    year      = {1997
}% ------------------------------------------------------------------------

@article{ChenEtAl:05,
    Author = {Z. Chen and T. Menzies and D. Port and B. Boehm},
    Title = {Finding the Right Data for Software Cost Modeling},
    Journal = {IEEE Software},
    Volume = {22},
    Pages = {38--46},
    Year = {2005}
}% ------------------------------------------------------------------------

@Book{halstead77,
    Author    = "M.H. Halstead",
    Title     = "Elements of Software Science",
    Publisher = "Elsevier ",
    Year      = 1977
}% ------------------------------------------------------------------------

@inproceedings{KirsoppShepperd:02,
    author  = {C. Kirsopp and M. Shepperd},
    title = {Case and Feature Subset Selection in Case-Based Software Project Effort Prediction},
    booktitle = {22nd SGAI International Conference on Knowledge-Based Systems and Applied Artificial Intelligence}
    publisher={Springer-Verlag},
    year={2002}
}% ------------------------------------------------------------------------

@article{KhoshgoftaarEtAl:05,
    Author = {T.M. Khoshgoftaar and N. Seliya and K. Gao},
    Title = {Assessment of a New Three-Group Software Quality Classification Technique: An Empirical Case Study},
    Journal = {Empirical Software Engineering},
    Volume = {10},
    Number = {2},
    Pages = {183-218},
    Year = {2005}
}% ------------------------------------------------------------------------

@ARTICLE{YL04b,
    author =        "L. Yu and H. Liu",
    title =         "Efficient Feature Selection via Analysis of Relevance and Redundancy",
    journal =       "Journal of Machine Learning Research",
    year =          "2004",
    volume =        "5",
    pages =         "1205--24"
}% ------------------------------------------------------------------------

@MISC{PROMISERep,
    author =       {G. Boetticher and T. Menzies and T. Ostrand},
    title =        {PROMISE Repository of Empirical Software Engineering Data},
    howpublished = {West Virginia University, Department of Computer Science},
    year =         {2007}
    url =          {http://promisedata.org/repository}
}% ------------------------------------------------------------------------

@article{batista:04,
    author = {G. Batista and R. C. Prati and M. C. Monard},
    title =        {{A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data}},
    journal =      {SIGKDD Explorations Newsletter},
    volume =       {6},
    number =       {1},
    pages =        {20-29},
    editors =      {Nitesh Chawla, Nathalie Japkowicz, Aleksander Kolcz},
    year =         {2004},
    note =         {Special issue on Learning from Imbalanced Datasets. \url{http://www.acm.org/sigs/sigkdd/explorations/issue6-1.htm}},
    %url = {citeseer.ist.psu.edu/article/batista04study.html}
}% ------------------------------------------------------------------------

@inproceedings{kubatMatwin97,
    author = "Miroslav Kubat and Stan Matwin",
    title = "Addressing the Curse of Imbalanced Training Sets: One-Sided Selection",
    booktitle = "Proc. 14th International Conference on Machine Learning",
    publisher = "Morgan Kaufmann",
    pages = "179--186",
    year = "1997",
    %url = "citeseer.ist.psu.edu/kubat97addressing.html"
}% ------------------------------------------------------------------------

@inproceedings{YasutakaEtAl:07,
    AUTHOR =       {Yasutaka Kamei and Akito Monden and Shinsuke Matsumoto and Takeshi Kakimotoand Ken-ichi Matsumoto},
    TITLE =        {The Effects of Over and Under Sampling on Fault-prone Module Detection},
    BOOKTITLE =    {Empirical Software Engineering and Measurement (ESEM 2007)},
    YEAR =         {2007},
    pages =        {196--204},
    month =        {September},
}% ------------------------------------------------------------------------

@INPROCEEDINGS{MenziesStefano04,
    AUTHOR =       {T. Menzies and J.S. {Di Stefano}},
    TITLE =        {How Good is your Blind Spot Sampling Policy},
    BOOKTITLE =    {Eighth IEEE International Symposium on High Assurance Systems Engineering, (HASE 2004},
    YEAR =         {2004},
    pages =        {129--138},
    month =        {25-26 March 2004},
}% ------------------------------------------------------------------------

@INPROCEEDINGS{MenziesEtAl04,
    AUTHOR =       {T. Menzies and J. DiStefano and A. Orrego and R. Chapman},
    TITLE =        {Assessing Predictors of Software Defects},
    BOOKTITLE =    {Workshop on Predictive Software Models (PSM 2004)},
    YEAR =         {2004}
}% ------------------------------------------------------------------------

@ARTICLE{MenziesEtAl07,
    title={Data Mining Static Code Attributes to Learn Defect Predictors},
    author={Tim Menzies and Jeremy Greenwald and Art Frank},
    journal={Transactions on Software Engineering},
    year={Jan. 2007},
    volume={33},
    number={1},
    pages={2--13},
    keywords={data mining, learning (artificial intelligence), program diagnostics, program testing, software qualityMcCabes versus Halstead, data mining, defect predictor learning, lines of code counts, resource-bound exploration, static code attributes},
    doi={10.1109/TSE.2007.256941},
    ISSN={0098-5589}
}% ------------------------------------------------------------------------

@inproceedings{Kutlubay07,
    author = {Onur Kutlubay and Burak Turhan and Ayse B. Bener},
    title = {A Two-Step Model for Defect Density Estimation},
    booktitle = {Proceedings of the 33rd EUROMICRO Conference on Software Engineering and Advanced Applications (EUROMICRO'07)},
    year = {2007},
    isbn = {0-7695-2977-1},
    pages = {322--332},
    doi = {http://dx.doi.org/10.1109/EUROMICRO.2007.13},
    publisher = {IEEE Computer Society},
    address = {Washington, DC, USA},
 }% ------------------------------------------------------------------------

@ARTICLE{SeiffertEtAl07,
    title={An Empirical Study of the Classification Performance of Learners on Imbalanced and Noisy Software Quality Data},
    author={Chris Seiffert and Taghi M. Khoshgoftaar Jason {Van Hulse}  and Andres Folleco},
    journal={IEEE International Conference on Information Reuse and Integration (IRI 2007). },
    year={13--15 Aug. 2007},
    pages={651--658},
    %doi={10.1109/IRI.2007.4296694},
    %ISSN={}
}% ------------------------------------------------------------------------

@inproceedings{VanHulse+EtAl:2007,
    author = {Jason {Van Hulse} and Taghi M. Khoshgoftaar and Amri Napolitano},
    title = {Experimental Perspectives on Learning from Imbalanced Data},
    booktitle = {Proceedings of the 24th International Conference on Machine Learning (ICML07)},
    year = {2007},
    isbn = {978-1-59593-793-3},
    pages = {935--942},
    location = {Corvalis, Oregon},
    doi = {http://doi.acm.org/10.1145/1273496.1273614},
    publisher = {ACM},
    address = {New York, NY, USA},
 }% ------------------------------------------------------------------------

@misc{Asuncion+Newman:2007 ,
    author = "A. Asuncion, D.J. Newman",
    year = "2007",
    title = "{UCI} Machine Learning Repository",
    url = "http://www.ics.uci.edu/$\sim$mlearn/{MLR}epository.html",
    institution = "University of California, Irvine, School of Information and Computer Sciences"
}% ------------------------------------------------------------------------

@INPROCEEDINGS{BarandelaEtAl:2004,
    AUTHOR = {Ricardo Barandela and Rosa M. Valdovinos and J.Salvador Sanchez and Francesc J. Ferri},
    TITLE = {The Imbalanced Training Sample Problem: Under or over sampling\?},
    BOOKTITLE = {In Joint IAPR International Workshops on Structural, Syntactic, and Statistical Pattern Recognition (SSPR/SPR04), Lecture Notes in Computer Science 3138},
    YEAR = {2004},
    pages = {806\96-814}
}% ------------------------------------------------------------------------

@article{ChawlaEtAl:2002,
    author = {Nitesh V. Chawla and Kevin W. Bowyer, Lawrence O. Hall and W. Philip Kegelmeyer},
    title = {SMOTE: Synthetic Minority Over-sampling Technique},
    journal = {Journal of Artificial Intelligence and Research},
    volume = {16},
    pages = {321--357},
    year = {2002},
    %url = "http://citeseer.ist.psu.edu/chawla02smote.html"
}% ------------------------------------------------------------------------

@article{Jo+Japkowicz:2004,
    author = {Taeho Jo and Nathalie Japkowicz},
    title = {Class Imbalances versus Small Disjuncts},
    journal = {SIGKDD Explor. Newsl.},
    volume = {6},
    number = {1},
    year = {2004},
    issn = {1931-0145},
    pages = {40--49},
    /doi = {http://doi.acm.org/10.1145/1007730.1007737},
    publisher = {ACM},
    address = {New York, NY, USA},
}% ------------------------------------------------------------------------

@INPROCEEDINGS{HanEtAl:2005,
    AUTHOR = {Hui Han and Wen-Yuan Wang and Bing-Huan Mao},
    TITLE = {Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning},
    BOOKTITLE = {Advances in Intelligent Computing International Conference on Intelligent Computing, ICIC 2005, Lecture Notes in Computer Science 3644},
    YEAR = {August 23-26, 2005},
}% ------------------------------------------------------------------------

@ARTICLE{Tomek:1976,
    AUTHOR =       {I. Tomek},
    TITLE =        {Two Modifications of CNN},
    JOURNAL =      {IEEE Transactions on Systems, Man and Cybernetics},
    YEAR =         {1976},
    volume =       {6},
    number =       {11},
    pages =        {769--772},
    month =        {November}
}% ------------------------------------------------------------------------

@ARTICLE{Hart:1968,
    title={The Condensed Nearest Neighbor Rule (Corresp.)},
    author={P. Hart},
    journal={IEEE Transactions on Information Theory},
    year={May 1968},
    volume={14},
    number={3},
    pages={515--516},
    ISSN={0018-9448}
}% ------------------------------------------------------------------------

@article{Guo2004,
    author = {Hongyu Guo and Herna L. Viktor},
    title = {Learning from Imbalanced Data Sets with Boosting and Data Generation: the DataBoost-IM approach},
    journal = {SIGKDD Explor. Newsl.},
    volume = {6},
    number = {1},
    year = {2004},
    issn = {1931-0145},
    pages = {30--39},
    doi = {http://doi.acm.org/10.1145/1007730.1007736},
    publisher = {ACM},
    address = {New York, NY, USA},
}% ------------------------------------------------------------------------

@ARTICLE{Wilson:1972,
    title={Asymptotic Properties of Nearest Neighbor Rules Using Edited Data},
    author={Wilson, Dennis L.},
    journal={IEEE Transactions on Systems, Man and Cybernetics},
    year={July 1972},
    volume={2},
    number={3},
    pages={408-421},
    abstract={The convergence properties of a nearest neighbor rule that uses an editing procedure to reduce the number of preclassified samples and to improve the performance of the rule are developed. Editing of the preclassified samples using the three-nearest neighbor rule followed by classification using the single-nearest neighbor rule with the remaining preclassified samples appears to produce a decision procedure whose risk approaches the Bayes' risk quite closely in many problems with only a few preclassified samples. The asymptotic risk of the nearest neighbor rules and the nearest neighbor rules using edited preclassified samples is calculated for several problems.},
    doi={10.1109/TSMC.1972.4309137},
    ISSN={0018-9472},
}% ------------------------------------------------------------------------

@ARTICLE{4027145,
    title={Data Mining Static Code Attributes to Learn Defect Predictors},
    author={T. Menzies and J. Greenwald and A. Frank},
    journal={Transactions on Software Engineering},
    year={2007},
    volume={33},
    number={1},
    pages={2--13},
    keywords={data mining, learning (artificial intelligence), program diagnostics, program testing, software qualityMcCabes versus Halstead, data mining, defect predictor learning, lines of code counts, resource-bound exploration, static code attributes},
    doi={10.1109/TSE.2007.256941},
    ISSN={0098-5589}
}% ------------------------------------------------------------------------

@ARTICLE{4271036,
    title={Applying Novel Resampling Strategies To Software Defect Prediction},
    author={Lourdes Pelayo and Scott Dick},
    journal={Annual Meeting of the North American Fuzzy Information Processing Society (NAFIPS'07)},
    year={24--27 June 2007},
    volume={},
    number={},
    pages={69--72},
    abstract={Due to the tremendous complexity and sophistication of software, improving software reliability is an enormously difficult task. We study the software defect prediction problem, which focuses on predicting which modules will experience a failure during operation. Numerous studies have applied machine learning to software defect prediction; however, skewness in defect-prediction datasets usually undermines the learning algorithms. The resulting classifiers will often never predict the faulty (minority0 class. This problem is well known in machine learning and is often referred to as learning from imbalanced datasets. We examine stratification, a widely used technique for learning imbalanced data that has received little attention in software defect prediction. Our experiments are focused on the SMOTE technique, which is a method of over-sampling minority-class examples. Our goal is to determine if SMOTE can improve recognition of defect-prone modules, and at what cost. Our experiments demonstrate that after SMOTE resampling, we have a more balanced classification. We found an improvement of at least 23% in the average geometric mean classification accuracy on four benchmark datasets.},
    doi={10.1109/NAFIPS.2007.383813},
    ISSN={},
}% ------------------------------------------------------------------------

@ARTICLE{Li+Reformat:2007,
    title={A Practical Method for the Software Fault-prediction},
    author={Zhan Li and Marek Reformat},
    journal={IEEE International Conference Information Reuse and Integration (IRI 2007)},
    year={13-15 Aug. 200},
    volume={},
    number={},
    pages={659--666},
    abstract={In the paper, a novel machine learning method, SimBoost, is proposed to handle the software fault-prediction problem when highly skewed datasets are used. Although the method, proved by empirical results, can make the datasets much more balanced, the accuracy of the prediction is still not satisfactory. Therefore, a fuzzy-based representation of the software module fault state has been presented instead of the original faulty/non-faulty one. Several experiments were conducted using datasets from NASA Metrics Data Program. The discussion of the results of experiments is provided.},
    doi={10.1109/IRI.2007.4296695},
    ISSN={1-4244-1500-4},
}% ------------------------------------------------------------------------
%@misc{hall98correlationbased,
%    author = "M. Hall",
%    title = "Correlation-based Feature Selection for Machine Learning",
%    text = "Hall, M. A. 1998. Correlation-based Feature Selection for Machine Learning. Ph.D diss. Hamilton, NZ: Waikato University, Department of Computer Science.",
%    year = "1998",
%    %url = "citeseer.ist.psu.edu/hall99correlationbased.html"
}% ------------------------------------------------------------------------

@inproceedings{liuSetiono96probabilistic,
    author = "Huan Liu and Rudy Setiono",
    title = "A Probabilistic Approach to Feature Selection - A Filter Solution",
    booktitle = "International Conference on Machine Learning",
    pages = "319--327",
    year = "1996",
    %url = "citeseer.ist.psu.edu/321378.html"
}% ------------------------------------------------------------------------

@book{WohlinEtAl2000experimentation,
    author = {Claes Wohlin and Per Runeson and Martin H\"{o}st and Magnus C. Ohlsson and Bj\"{o}orn Regnell and Anders Wessl\'{e}n},
    title = {Experimentation in Software Engineering: An Introduction},
    year = {2000},
    isbn = {0-7923-8682-5},
    publisher = {Kluwer Academic Publishers},
    address = {Norwell, MA, USA}
}% ------------------------------------------------------------------------


@ARTICLE{Kitchenham2007UnbalancedDS,
    title={A procedure for Analyzing Unbalanced Datasets},
    author={Barbara Kitchenham},
    journal={IEEE Transactions on Software Engineering},
    year={1998},
    volume={24},
    number={4},
    pages={278--301},
    abstract={This paper describes a procedure for analyzing unbalanced datasets that include many nominal- and ordinal-scale factors. Such datasets are often found in company datasets used for benchmarking and productivity assessment. The two major problems caused by lack of balance are that the impact of factors can be concealed and that spurious impacts can be observed. These effects are examined with the help of two small artificial datasets. The paper proposes a method of forward pass residual analysis to analyze such datasets. The analysis procedure is demonstrated on the artificial datasets and then applied to the COCOMO dataset. The paper ends with a discussion of the advantages and limitations of the analysis procedure},
    keywords={software metricsCOCOMO dataset, analysis of variance, benchmarking, forward pass residual analysis, productivity assessment, residual analysis, software metrics, statistical analysis, unbalanced datasets},
    doi={10.1109/32.677185},
    ISSN={0098-5589}
}% ------------------------------------------------------------------------

@ARTICLE{Rodriguez2007AttSelection,
    title={Detecting Fault Modules Applying Feature Selection to Classifiers},
    author={D. Rodriguez and R. Ruiz, R. and J. Cuadrado, J. and J. Aguilar-Ruiz},
    journal={Information Reuse and Integration, 2007. IRI 2007. IEEE International Conference on},
    year={13-15 Aug. 2007},
    volume={},
    number={},
    pages={667--672},
    abstract={At present, automated data collection tools allow us to collect large amounts of information, not without associated problems. This paper, we apply feature selection to several software engineering databases selectingat attributes with the final aim that project managers can have a better global vision of the data they manage. In this paper, we make use of attribute selection techniques in different datasets publicly available (PROMISE repository), and different data mining algorithms for classification to defect faulty modules. The results show that in general, smaller datasets with less attributes maintain or improve the prediction capability with less attributes than the original datasets.},
    doi={10.1109/IRI.2007.4296696},
    ISSN={}
}
